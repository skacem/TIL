{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "558aa9af-48db-4849-b4a1-4ebeda55c49a",
   "metadata": {},
   "source": [
    "# Session 2 - Writing Web Crawlers:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0cd438b-036f-478e-a029-41950f7ed5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fa13e7-fc7b-4262-8633-9d11dc0da73f",
   "metadata": {},
   "source": [
    "\n",
    "## A simple One Page Crawler\n",
    "\n",
    "Let's build a web crawler that gets the all time top 100 movies of a given genre:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "938b5b0b-8c86-40e8-93c5-85381a1d7b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first web crawler\n",
    "def top_100_movies(genre):\n",
    "    headers = {\n",
    "        'user-agent': \n",
    "        'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.82 Safari/537.36',\n",
    "        'Cache-Control':'no-cache'\n",
    "    }\n",
    "    \n",
    "    link = 'https://www.rottentomatoes.com/top/bestofrt/top_100_' + genre.lower() + '_movies/'\n",
    "    movie_list = []\n",
    "    r = requests.get(link, headers=headers, timeout=20)\n",
    "    soup = bs(r.text, \"lxml\")\n",
    "    movies = soup.find('table', class_=\"table\").find_all('a', class_=\"unstyled articleLink\")\n",
    "    for movie in movies:\n",
    "        movie_list.append(movie.getText().strip())\n",
    "    return movie_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a44b746-4a11-4f59-b007-e59caa37c62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Animation: Toy Story 4 (2019), Spider-Man: Into the Spider-Verse (2018), Inside Out (2015).\n",
      "Horror: Us (2019), Get Out (2017), The Cabinet of Dr. Caligari (Das Cabinet des Dr. Caligari) (1920).\n",
      "Drama: Black Panther (2018), Citizen Kane (1941), Parasite (Gisaengchung) (2019).\n",
      "Comedy: It Happened One Night (1934), Modern Times (1936), Toy Story 4 (2019).\n",
      "Classics: It Happened One Night (1934), Modern Times (1936), Citizen Kane (1941).\n",
      "Documentary: Won't You Be My Neighbor? (2018), I Am Not Your Negro (2017), Apollo 11 (2019).\n",
      "Romance: It Happened One Night (1934), Casablanca (1942), The Philadelphia Story (1940).\n",
      "Mystery & Suspense: Citizen Kane (1941), Knives Out (2019), Us (2019).\n",
      "Action & Adventure: Black Panther (2018), Avengers: Endgame (2019), Mission: Impossible - Fallout (2018).\n",
      "Science_Fiction & Fantasy: Black Panther (2018), The Wizard of Oz (1939), Avengers: Endgame (2019).\n",
      "Art_House & International: Parasite (Gisaengchung) (2019), The Cabinet of Dr. Caligari (Das Cabinet des Dr. Caligari) (1920), Seven Samurai (Shichinin no Samurai) (1956).\n"
     ]
    }
   ],
   "source": [
    "genres = ['animation', 'horror', 'drama', 'comedy', \n",
    "              'classics', 'documentary', 'romance',\n",
    "             'mystery__suspense', 'action__adventure',\n",
    "             'science_fiction__fantasy','art_house__international']\n",
    "\n",
    "\n",
    "# 3 top movies in each category\n",
    "for genre in genres:\n",
    "    print(f\"{genre.title().replace('__', ' & ')}: {', '.join(top_100_movies(genre)[:3])}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0ba2c9-2f3d-4f2c-817f-981f244f42c6",
   "metadata": {},
   "source": [
    "### Traversing a Single Domain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30fe6644-94fc-42d0-9063-ff3ca5baeed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('http://en.wikipedia.org/wiki/Kevin_Bacon')\n",
    "soup = bs(r.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0095b7d4-3a59-4010-bcd5-73379601857b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "887\n"
     ]
    }
   ],
   "source": [
    "# we need to get the links pointing to the same domain we are in\n",
    "# Let's first get all links in the webpage\n",
    "\n",
    "# Links start with the a tag:\n",
    "lilst = []\n",
    "for link in soup.find_all('a'):\n",
    "    if 'href' in link.attrs:\n",
    "        lilst.append(link.attrs['href'])\n",
    "print(len(lilst))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bd0cfe-db50-4f6b-a6db-882e51415a39",
   "metadata": {},
   "source": [
    "There are almost 900 links in this one single wiki page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e5f833f-3d87-45eb-aab3-5d82a977ae13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/wiki/Philadelphia,_Pennsylvania',\n",
       " '/wiki/Kyra_Sedgwick',\n",
       " '/wiki/Sosie_Bacon',\n",
       " '#cite_note-1',\n",
       " '/wiki/Edmund_Bacon_(architect)',\n",
       " '/wiki/Michael_Bacon_(musician)',\n",
       " '/wiki/Holly_Near',\n",
       " 'http://baconbros.com/',\n",
       " '#cite_note-2',\n",
       " '#cite_note-actor-3']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lilst[5:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca8904e-f139-49ed-a49f-d3029b1b5a4d",
   "metadata": {},
   "source": [
    "We want only wiki links from the body content or what has to do Kevin Bacon. We don't care about the footer, header or sidebars. \n",
    "We will need to use regular expressions such as `^(/wiki/)((?!:).)*$\")`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fe565ad-b1a0-4702-9ddd-27abcbcadeac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "406\n"
     ]
    }
   ],
   "source": [
    "lilst = []\n",
    "for link in soup.find('div', {'id':'bodyContent'}).find_all('a', href=re.compile('^(/wiki/)((?!:).)*$')): \n",
    "    if 'href' in link.attrs:\n",
    "        lilst.append(link.attrs['href'])\n",
    "print(len(lilst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4664a266-5873-444f-a3c5-ed79b61fafd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/wiki/Apollo_13_(film)',\n",
       " '/wiki/Mystic_River_(film)',\n",
       " '/wiki/Balto_(film)',\n",
       " '/wiki/Sleepers',\n",
       " '/wiki/The_Woodsman_(2004_film)',\n",
       " '/wiki/Animal_House',\n",
       " '/wiki/Diner_(1982_film)',\n",
       " '/wiki/Tremors_(1990_film)',\n",
       " '/wiki/Crazy,_Stupid,_Love',\n",
       " '/wiki/Friday_the_13th_(1980_film)']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lilst[10:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2346c4-05f2-4391-9a0f-863215dd49db",
   "metadata": {},
   "source": [
    "That looks good. \n",
    "We need to put that in a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a896118f-8a24-4493-bb14-0fbd3c18d4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import random\n",
    "\n",
    "random.seed(datetime.datetime.now()) \n",
    "\n",
    "def getLinks(articleUrl):\n",
    "    html = requests.get('http://en.wikipedia.org{}'.format(articleUrl)) \n",
    "    soup = bs(html.text, 'html.parser')\n",
    "    return soup.find('div', {'id':'bodyContent'}).find_all('a',href=re.compile('^(/wiki/)((?!:).)*$'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00ed393a-761d-4d3b-a1ee-66b6c8f58e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = list(getLinks('/wiki/Kevin_Bacon'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45f14ca5-bc07-4503-9395-263029dd9231",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = links[2:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cae7d6c-6a80-43fc-8e2d-a609bade4a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "while len(links) > 0:\n",
    "    newArticle = links[random.randint(0, len(links)-1)].attrs['href'] \n",
    "    print(newArticle)\n",
    "    links = getLinks(newArticle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15f1328-2d0f-4685-aa13-59b65c3fa2c1",
   "metadata": {},
   "source": [
    "To avoid crawling the same page twice and loops, it is extremely important that all internal links discovered are formatted consistently, and kept in a running set for easy lookups, while the program is running.\n",
    "\n",
    "In the next session we are going to see how to automatically extract data from different pageweb sources. Stay connected!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37afb9b-dda8-436a-ab61-9134686c9c07",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
